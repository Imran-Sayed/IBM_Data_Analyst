{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collecting Job Data Using APIs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Collect job data using Jobs API\n",
    "*   Store the collected data into an excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><strong>Note: Before starting with the assignment make sure to read all the instructions and then move ahead with the coding part.</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the actual lab, firstly you need to click on the [Jobs_API](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Jobs_API.ipynb) notebook link. The file contains flask code which is required to run the Jobs API data.\n",
    "\n",
    "Now, to run the code in the file that opens up follow the below steps.\n",
    "\n",
    "Step1: Download the file. \n",
    "\n",
    "Step2: Upload the file into your current Jupyter environment using the upload button in your Jupyter interface. Ensure that the file is in the same folder as your working .ipynb file.\n",
    "\n",
    "Step 2: If working in a local Jupyter environment, use the \"Upload\" button in your Jupyter interface to upload the Jobs_API notebook into the same folder as your current .ipynb file.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Upload.PNG\">\n",
    "\n",
    "Step3:  Open the Jobs_API notebook, and run all the cells to start the Flask application. Once the server is running, you can access the API from the URL provided in the notebook.\n",
    "\n",
    "If you want to learn more about flask, which is optional, you can click on this link [here](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/FLASK_API.md.html).\n",
    "\n",
    "Once you run the flask code, you can start with your assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Used in this Assignment\n",
    "\n",
    "The dataset used in this lab comes from the following source: https://www.kaggle.com/promptcloud/jobs-on-naukricom under the under a **Public Domain license**.\n",
    "\n",
    "> Note: We are using a modified subset of that dataset for the lab, so to follow the lab instructions successfully please use the dataset provided with the lab, rather than the dataset from the original source.\n",
    "\n",
    "The original dataset is a csv. We have converted the csv to json as per the requirement of the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you attempt the actual lab, here is a fully solved warmup exercise that will help you to learn how to access an API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an API, let us find out who currently are on the International Space Station (ISS).<br> The API at [http://api.open-notify.org/astros.json](http://api.open-notify.org/astros.json?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ) gives us the information of astronauts currently on ISS in json format.<br>\n",
    "You can read more about this API at [http://open-notify.org/Open-Notify-API/People-In-Space/](http://open-notify.org/Open-Notify-API/People-In-Space?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests # you need this module to make an API call\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_url = \"http://api.open-notify.org/astros.json\" # this url gives use the astronaut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(api_url) # Call the API using the get method and store the\n",
    "                                # output of the API call in a variable called response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if response.ok:             # if all is well() no errors, no network timeouts)\n",
    "    data = response.json()  # store the result in json format in a variable called data\n",
    "                            # the variable data is of type dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'craft': 'ISS', 'name': 'Oleg Kononenko'}, {'craft': 'ISS', 'name': 'Nikolai Chub'}, {'craft': 'ISS', 'name': 'Tracy Caldwell Dyson'}, {'craft': 'ISS', 'name': 'Matthew Dominick'}, {'craft': 'ISS', 'name': 'Michael Barratt'}, {'craft': 'ISS', 'name': 'Jeanette Epps'}, {'craft': 'ISS', 'name': 'Alexander Grebenkin'}, {'craft': 'ISS', 'name': 'Butch Wilmore'}, {'craft': 'ISS', 'name': 'Sunita Williams'}, {'craft': 'Tiangong', 'name': 'Li Guangsu'}, {'craft': 'Tiangong', 'name': 'Li Cong'}, {'craft': 'Tiangong', 'name': 'Ye Guangfu'}], 'number': 12, 'message': 'success'}\n"
     ]
    }
   ],
   "source": [
    "print(data)   # print the data just to check the output or for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of astronauts currently on ISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(data.get('number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"people\": [\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Oleg Kononenko\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Nikolai Chub\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Tracy Caldwell Dyson\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Matthew Dominick\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Michael Barratt\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Jeanette Epps\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Alexander Grebenkin\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Butch Wilmore\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"ISS\",\n",
      "            \"name\": \"Sunita Williams\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"Tiangong\",\n",
      "            \"name\": \"Li Guangsu\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"Tiangong\",\n",
      "            \"name\": \"Li Cong\"\n",
      "        },\n",
      "        {\n",
      "            \"craft\": \"Tiangong\",\n",
      "            \"name\": \"Ye Guangfu\"\n",
      "        }\n",
      "    ],\n",
      "    \"number\": 12,\n",
      "    \"message\": \"success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the names of the astronauts currently on ISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 astronauts on ISS\n",
      "And their names are :\n",
      "Oleg Kononenko\n",
      "Nikolai Chub\n",
      "Tracy Caldwell Dyson\n",
      "Matthew Dominick\n",
      "Michael Barratt\n",
      "Jeanette Epps\n",
      "Alexander Grebenkin\n",
      "Butch Wilmore\n",
      "Sunita Williams\n",
      "Li Guangsu\n",
      "Li Cong\n",
      "Ye Guangfu\n"
     ]
    }
   ],
   "source": [
    "astronauts = data.get('people')\n",
    "print(\"There are {} astronauts on ISS\".format(len(astronauts)))\n",
    "print(\"And their names are :\")\n",
    "for astronaut in astronauts:\n",
    "    print(astronaut.get('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope the warmup was helpful. Good luck with your next lab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Collect Jobs Data using Jobs API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Determine the number of jobs currently open for various technologies  and for various locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of job postings for the following locations using the API:\n",
    "\n",
    "* Los Angeles\n",
    "* New York\n",
    "* San Francisco\n",
    "* Washington DC\n",
    "* Seattle\n",
    "* Austin\n",
    "* Detroit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json#### Write a function to get the number of jobs for the Python technology.<br>\n",
    "> Note: While using the lab you need to pass the **payload** information for the **params** attribute in the form of **key** **value** pairs.\n",
    "  Refer the ungraded **rest api lab** in the course **Python for Data Science, AI & Development**  <a href=\"https://www.coursera.org/learn/python-for-applied-data-science-ai/ungradedLti/P6sW8/hands-on-lab-access-rest-apis-request-http?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\">link</a>\n",
    "  \n",
    " ##### The keys in the json are \n",
    " * Job Title\n",
    " \n",
    " * Job Experience Required\n",
    " \n",
    " * Key Skills\n",
    " \n",
    " * Role Category\n",
    " \n",
    " * Location\n",
    " \n",
    " * Functional Area\n",
    " \n",
    " * Industry\n",
    " \n",
    " * Role \n",
    " \n",
    "You can also view  the json file contents  from the following <a href = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\">json</a> URL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_url=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "def get_number_of_jobs_T(technology):\n",
    "    #your code goes here\n",
    "    return technology,number_of_jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function for Python and checking if it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse JSON data\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "response = requests.get(api_url)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Id': 0, 'Job Title': 'Digital Media Planner', 'Job Experience Required': '5 - 10 yrs', 'Key Skills': 'Media Planning| Digital Media', 'Role Category': 'Advertising', 'Location': 'Los Angeles', 'Functional Area': 'Marketing , Advertising , MR , PR , Media Planning', 'Industry': 'Advertising, PR, MR, Event Management', 'Role': 'Media Planning Executive/Manager'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Id\": 0,\n",
      "    \"Job Title\": \"Digital Media Planner\",\n",
      "    \"Job Experience Required\": \"5 - 10 yrs\",\n",
      "    \"Key Skills\": \"Media Planning| Digital Media\",\n",
      "    \"Role Category\": \"Advertising\",\n",
      "    \"Location\": \"Los Angeles\",\n",
      "    \"Functional Area\": \"Marketing , Advertising , MR , PR , Media Planning\",\n",
      "    \"Industry\": \"Advertising, PR, MR, Event Management\",\n",
      "    \"Role\": \"Media Planning Executive/Manager\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function to find number of jobs in US for a \"Key Skills\" of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Skills :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_jobs_T(technology):\n",
    "    count = 0\n",
    "    for job in data:\n",
    "        if \"Key Skills\" in job and technology.lower() in job[\"Key Skills\"].lower():\n",
    "            count += 1\n",
    "    return technology, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', 25114)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_jobs_T(\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Location :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_number_of_jobs_L(location):\n",
    "    count = 0\n",
    "    for job in data:\n",
    "        if \"Location\" in job and location.lower() in job[\"Location\"].lower():\n",
    "            count += 1\n",
    "    return location, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function for Los Angeles and check if it is working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Los Angeles', 640)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_jobs_L(\"Los Angeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the results in an excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the API for all the given \"technologies\" above and write the results in an excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python list of all \"locations\" for which you need to find the number of jobs postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "key_skills_set = set()\n",
    "\n",
    "for job in data:\n",
    "    if \"Key Skills\" in job:\n",
    "        raw = job[\"Key Skills\"]\n",
    "        \n",
    "        # Normalize everything to lowercase to avoid duplicates like \"Python\" and \"python\"\n",
    "        raw = raw.lower()\n",
    "        \n",
    "        # Replace common separators with a pipe\n",
    "        raw = re.sub(r\"[;,|/\\\\\\\"\\n\\r\\t]+\", \"|\", raw)\n",
    "        \n",
    "        # Remove extra spaces and non-alphabetical junk from ends\n",
    "        skills = [skill.strip() for skill in raw.split(\"|\") if skill.strip()]\n",
    "        \n",
    "        # Filter out anything that's too short or junky\n",
    "        for skill in skills:\n",
    "            if len(skill) > 1 and re.search(r\"[a-zA-Z]\", skill):  # must have at least one letter\n",
    "                key_skills_set.add(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14144"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_skills_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning + normalization + de-duplication logic, \n",
    "#### Step-by-step cleanup strategy:\n",
    "#### 1. Lowercase everything.\n",
    "#### 2. Split by all possible delimiters: |, ,, ;, /, etc.\n",
    "#### 3. Strip extra spaces, punctuation.\n",
    "#### 4. Ignore pure junk (like single letters or weird strings).\n",
    "#### 5. Normalize variants like:\n",
    "#### 6. c++, c plus plus, c\\+\\+ → c++\n",
    "#### 7. asp.net, asp net, .net → maybe keep distinct or group .net family\n",
    "#### 8. Avoid full job titles like \"java developer\" — only pick \"java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Optional normalization dictionary\n",
    "normalize_map = {\n",
    "    \"c plus plus\": \"c++\",\n",
    "    r\"c\\+\\+\": \"c++\",  # ← raw string here avoids escape warning\n",
    "    \"c#\": \"c#\",\n",
    "    \"c sharp\": \"c#\",\n",
    "    \"asp net\": \"asp.net\",\n",
    "    \".net framework\": \".net\",\n",
    "    \".net developer\": \".net\",\n",
    "    \"ms sql\": \"sql\",\n",
    "    \"microsoft sql server\": \"sql server\",\n",
    "    \"js\": \"javascript\",\n",
    "    \"py\": \"python\"\n",
    "}\n",
    "key_skills_set = set()\n",
    "\n",
    "for job in data:\n",
    "    if \"Key Skills\" in job:\n",
    "        raw = job[\"Key Skills\"].lower()\n",
    "\n",
    "        # Normalize delimiters\n",
    "        raw = re.sub(r\"[;,/\\\\|\\n\\r\\t]+\", \"|\", raw)\n",
    "\n",
    "        # Tokenize\n",
    "        tokens = [t.strip() for t in raw.split(\"|\") if t.strip()]\n",
    "\n",
    "        for skill in tokens:\n",
    "            # Basic noise filtering\n",
    "            if len(skill) < 2 or not re.search(r\"[a-z]\", skill):\n",
    "                continue\n",
    "            \n",
    "            # Apply normalization mapping\n",
    "            if skill in normalize_map:\n",
    "                skill = normalize_map[skill]\n",
    "\n",
    "            # Remove long job titles like \"senior python developer\"\n",
    "            if len(skill.split()) > 3:\n",
    "                continue\n",
    "\n",
    "            key_skills_set.add(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13849"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_skills_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved code that:\n",
    "# ------- Handles multiple delimiters.\n",
    "# ------- Strips whitespace.\n",
    "# ------- Converts to lowercase.\n",
    "# ------- Applies some basic normalization.\n",
    "\n",
    "import re\n",
    "\n",
    "all_skills = []\n",
    "\n",
    "# Loop through each job record\n",
    "for record in data:\n",
    "    key_skills = record.get(\"Key Skills\", \"\")\n",
    "    \n",
    "    # Normalize separators to '|'\n",
    "    key_skills = re.sub(r\"[;,/]|\\\\|\\s+\\|\\s+|\\s{2,}\", \"|\", key_skills)\n",
    "    \n",
    "    # Split using '|'\n",
    "    skills = key_skills.split(\"|\")\n",
    "\n",
    "    # Clean each skill\n",
    "    for skill in skills:\n",
    "        clean_skill = skill.strip().lower()\n",
    "        if clean_skill:\n",
    "            all_skills.append(clean_skill)\n",
    "\n",
    "# Optional: Normalize common variations\n",
    "normalization_map = {\n",
    "    \"c plus plus\": \"c++\",\n",
    "    \"c++\": \"c++\",\n",
    "    \"c#\": \"c#\",\n",
    "    \"asp net\": \"asp.net\",\n",
    "    \".net\": \".net\",\n",
    "    \"sql server\": \"sql\",\n",
    "    \"ms sql\": \"sql\",\n",
    "    \"javascript\": \"javascript\",\n",
    "    \"js\": \"javascript\",\n",
    "    \"py\": \"python\"\n",
    "}\n",
    "    \n",
    "# Apply normalization\n",
    "normalized_skills = []\n",
    "for skill in all_skills:\n",
    "    normalized_skills.append(normalization_map.get(skill, skill))\n",
    "\n",
    "# Get unique skills\n",
    "unique_skills = set(normalized_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique skills: 14169\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique skills: {len(unique_skills)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample skills: ['vendor', 'territory management', 'consumer behavior', 'com', 'art & craft teacher', 'supply chain consultant', 'manpower planning', 'core banking', 'recovery manager', 'loyalty programs', 'solar thermal', 'automation engineering', 'automation', 'merchandiser', 'trims', 'vehicle loan', 'power plants', 'windchill', 'ic engines', 'background verification', 'sid', 'mcse', 'transfer agency', 'cost analysis', 'product sales', 'ionic framework', 'marketing promotions', 'electric', 'isometric', 'architectures', 'trade support', 'merchandising strategies', 'quality operations', 'turkish', 'service advisor', 'tests software', 'activemq', 'education counselling', 'mortgages loan', 'case studies', 'proven', 'vb .net', 'marketing analysis', 'pvc pipes', 'imds', 'internal control review', 'sap manufacturing management', 'win2012', 'appdynamic', 'business development head']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample skills:\", list(unique_skills)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method to clean up the data\n",
    "# 1. Replace all kinds of separators with a single |.\n",
    "# 2. Strip whitespace and remove empty entries.\n",
    "# 3. Normalize duplicates (\"c++\", \"c plus plus\", \"cplusplus\", etc.)\n",
    "# 4. Remove skills that are too short, contain only numbers or symbols.\n",
    "\n",
    "import re\n",
    "\n",
    "all_skills = []\n",
    "\n",
    "# Normalization dictionary\n",
    "normalization_map = {\n",
    "    \"c plus plus\": \"c++\",\n",
    "    \"cplusplus\": \"c++\",\n",
    "    \"c#\": \"c#\",\n",
    "    \"asp net\": \"asp.net\",\n",
    "    \"aspnet\": \"asp.net\",\n",
    "    \".net\": \".net\",\n",
    "    \"sql server\": \"sql\",\n",
    "    \"ms sql\": \"sql\",\n",
    "    \"mssql\": \"sql\",\n",
    "    \"js\": \"javascript\",\n",
    "    \"py\": \"python\",\n",
    "    \"node js\": \"node.js\",\n",
    "    \"nodejs\": \"node.js\",\n",
    "}\n",
    "\n",
    "# Pattern to unify separators: comma, semicolon, slash, pipe, etc.\n",
    "separator_pattern = r'[\\|,;/\\\\\"]+'\n",
    "\n",
    "for record in data:\n",
    "    raw_skills = record.get(\"Key Skills\", \"\")\n",
    "    \n",
    "    # Replace different separators with '|'\n",
    "    raw_skills = re.sub(separator_pattern, '|', raw_skills)\n",
    "    \n",
    "    # Split\n",
    "    skills = raw_skills.split('|')\n",
    "    \n",
    "    for skill in skills:\n",
    "        skill = skill.strip().lower()\n",
    "\n",
    "        # Normalize\n",
    "        skill = normalization_map.get(skill, skill)\n",
    "        \n",
    "        # Skip very short, numeric or empty entries\n",
    "        if len(skill) > 1 and not skill.isnumeric():\n",
    "            all_skills.append(skill)\n",
    "\n",
    "# Unique skills\n",
    "unique_skills = set(all_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14138"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming 'data' contains the loaded JSON list of job postings\n",
    "# and each posting has a \"Key Skills\" field (a string with '|' separated values)\n",
    "\n",
    "skill_counter = Counter()\n",
    "\n",
    "for job in data:\n",
    "    skills_str = job.get(\"Key Skills\", \"\")\n",
    "    if not skills_str:\n",
    "        continue\n",
    "    # Split the skills by '|', strip spaces\n",
    "    skills = [skill.strip().lower() for skill in skills_str.split('|') if skill.strip()]\n",
    "    skill_counter.update(skills)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df_skill_counts = pd.DataFrame(skill_counter.items(), columns=[\"Key Skill\", \"Job Count\"])\n",
    "\n",
    "# Sort by job count (descending)\n",
    "df_skill_counts = df_skill_counts.sort_values(by=\"Job Count\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save to Excel\n",
    "df_skill_counts.to_excel(\"key_skills_job_counts.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Locations:\n",
      "['Austin', 'Baltimore', 'Boston', 'Dallas', 'Detroit', 'Houston', 'Los Angeles', 'New Orleons', 'New York', 'Philadelphia', 'San Francisco', 'Seattle', 'Washington DC']\n"
     ]
    }
   ],
   "source": [
    "# Location\n",
    "\n",
    "location_set = set()\n",
    "\n",
    "for job in data:\n",
    "    if \"Location\" in job:\n",
    "        location_set.add(job[\"Location\"].strip())\n",
    "\n",
    "# Display the unique locations\n",
    "print(\"Unique Locations:\")\n",
    "print(sorted(location_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each location\n",
    "location_counter = Counter()\n",
    "\n",
    "for job in data:\n",
    "    location = job.get(\"Location\", \"\").strip()\n",
    "    if location:\n",
    "        location_counter[location] += 1\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df_location_counts = pd.DataFrame(location_counter.items(), columns=[\"Location\", \"Job Count\"])\n",
    "\n",
    "# Sort the DataFrame by job count in descending order\n",
    "df_location_counts = df_location_counts.sort_values(by=\"Job Count\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Export to Excel\n",
    "df_location_counts.to_excel(\"job_postings_by_location.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the similar way, you can try for below given technologies and results  can be stored in an excel sheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of job postings for the following languages using the API:\n",
    "\n",
    "*   C\n",
    "*   C#\n",
    "*   C++\n",
    "*   Java\n",
    "*   JavaScript\n",
    "*   Python\n",
    "*   Scala\n",
    "*   Oracle\n",
    "*   SQL Server\n",
    "*   MySQL Server\n",
    "*   PostgreSQL\n",
    "*   MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayushi Jain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n",
    "\n",
    "Lakshmi Holla\n",
    "\n",
    "Malika\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- | \n",
    "| 2022-01-19        | 0.3     | Lakshmi Holla        | Added changes in the markdown      |\n",
    "| 2021-06-25        | 0.2     | Malika            | Updated GitHub job json link       |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "prev_pub_hash": "61a35a07ad98492b710274ae0e52a0fdce2221e88e366133dd4a20370680fa8f"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
